# Real-time-Audio-Sentiment-Analysis
Real time Audio Sentiment Analysis for business using IA tools

Nowadays, gaining a quick understanding of human behavior through emotions and opinions expressed in spoken language is vital to improve customer satisfaction and offer better service.

With cross-modal interaction and AI (tools and pre-trained models in NLP), we can analyze large audio data in real-time, such as recorded conversations, customer service calls, or voice recordings, in order to identify and categorize emotions (from positive and neutral to sad and angry.



![Arquitecture_W](https://github.com/rayespinozah/Real-time-Audio-Sentiment-Analysis/assets/92163016/a37ad0ee-0033-4407-9364-e585d9a30c45)


Project details:
I utilized a pre-trained model called Whisper, developed by OpenAI, which incorporates 680k hours of multilingual and multitask data from various websites.
The Whisper model employs a Seq2seq architecture, utilizing deep learning techniques like transformer encoder and decoder.
This project uses an Automatic Speech Recognition (ASR) architecture.
I integrated Gradio, a tool for machine learning model integration and ensuring an easy user experience.
